"""
InsightFace AuraFace-v1 ê¸°ë°˜ ë°°ìš° ì¸ë±ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ê¸°ì¡´ CLIP ë²„ì „ê³¼ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ ì§€í•˜ë©´ì„œ InsightFace ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

ë‘ ê°€ì§€ ë°ì´í„°ì…‹ êµ¬ì¡°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:
1) í´ë” ê¸°ë°˜ (ê¶Œì¥):
   dataset_dir/
     ë°°ìš°ì´ë¦„A/*.jpg
     ë°°ìš°ì´ë¦„B/*.png
   => ê° í´ë”ì˜ ì´ë¯¸ì§€ ì„ë² ë”© í‰ê· ì„ ë°°ìš° ëŒ€í‘œ ë²¡í„°ë¡œ ì €ì¥

2) CSV ê¸°ë°˜:
   --csv file.csv (columns: name,image_path)
   => ê°™ì€ ì´ë¦„ì„ ê°€ì§„ ì´ë¯¸ì§€ë“¤ì„ ê·¸ë£¹í•‘í•˜ì—¬ í‰ê· 

ì¶œë ¥: backend/app/data/
  - embeddings.npy (shape: [N_actors, 512])
  - metadata.json (list[{name, image_rel}])
  - actors/ (ëŒ€í‘œ ì´ë¯¸ì§€ ë³µì‚¬ë³¸)
"""
from __future__ import annotations
import argparse
import csv
import json
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from PIL import Image

from backend.app.services.embeddings import image_embedding
from backend.app.services.search import DATA_DIR, ACTOR_IMAGES_DIR


def iter_folder(dataset_dir: Path) -> Dict[str, List[Path]]:
    """í´ë” êµ¬ì¡°ì—ì„œ ë°°ìš°ë³„ ì´ë¯¸ì§€ ê²½ë¡œ ë§¤í•‘ ìƒì„±"""
    mapping: Dict[str, List[Path]] = defaultdict(list)
    # embeddings í´ë”ëŠ” ë°°ìš°ë¡œ ì¸ì‹í•˜ì§€ ì•ŠìŒ
    for actor_dir in sorted([p for p in dataset_dir.iterdir() if p.is_dir() and p.name != "embeddings"]):
        name = actor_dir.name
        for img in actor_dir.rglob("*"):
            if img.suffix.lower() in {".jpg", ".jpeg", ".png", ".webp"}:
                mapping[name].append(img)
    return mapping


def iter_csv(csv_path: Path) -> Dict[str, List[Path]]:
    """CSV íŒŒì¼ì—ì„œ ë°°ìš°ë³„ ì´ë¯¸ì§€ ê²½ë¡œ ë§¤í•‘ ìƒì„±"""
    mapping: Dict[str, List[Path]] = defaultdict(list)
    with open(csv_path, "r", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        for row in reader:
            name = row["name"].strip()
            img_path = Path(row["image_path"]).expanduser().resolve()
            if img_path.exists():
                mapping[name].append(img_path)
    return mapping


def compute_actor_vectors(groups: Dict[str, List[Path]], clusters_per_actor: int = 1) -> Tuple[np.ndarray, List[Dict]]:
    """
    ë°°ìš°ë³„ ì´ë¯¸ì§€ë“¤ì„ InsightFace ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ê³  í‰ê·  ë²¡í„° ìƒì„±
    
    Args:
        groups: ë°°ìš° ì´ë¦„ -> ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ë§¤í•‘
        clusters_per_actor: ë°°ìš°ë‹¹ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (ê¸°ë³¸ 1)
        
    Returns:
        (embeddings_matrix, metadata_list)
    """
    ACTOR_IMAGES_DIR.mkdir(parents=True, exist_ok=True)
    vectors = []
    meta: List[Dict] = []
    
    total_actors = len(groups)
    processed = 0
    
    print(f"\nğŸ”® InsightFaceë¡œ ë°°ìš° ì¸ë±ìŠ¤ ìƒì„± ì‹œì‘ (ì´ {total_actors}ëª…)")
    print("=" * 60)
    
    for name, paths in sorted(groups.items()):
        if not paths:
            continue
            
        processed += 1
        print(f"\n[{processed}/{total_actors}] ì²˜ë¦¬ ì¤‘: {name} ({len(paths)}ì¥)")
        
        embs = []
        rep_rel = None
        face_detected_count = 0
        
        for i, p in enumerate(paths[:20]):  # ìµœëŒ€ 20ì¥ê¹Œì§€ ìƒ˜í”Œë§
            try:
                with open(p, "rb") as f:
                    emb = image_embedding(f.read(), image_path=str(p), use_cache=True)
                
                if emb is None:
                    print(f"  âš ï¸  {p.name}: ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨")
                    continue
                
                embs.append(emb)
                face_detected_count += 1
                
                # ì²« ë²ˆì§¸ ì„±ê³µí•œ ì´ë¯¸ì§€ë¥¼ ëŒ€í‘œ ì´ë¯¸ì§€ë¡œ ì €ì¥
                if rep_rel is None:
                    # ë°°ìš° ì´ë¦„ìœ¼ë¡œ í´ë” ìƒì„±
                    actor_folder = ACTOR_IMAGES_DIR / name
                    actor_folder.mkdir(exist_ok=True)
                    
                    # 001.jpg í˜•ì‹ìœ¼ë¡œ ì €ì¥
                    target = actor_folder / f"001{p.suffix.lower()}"
                    if not target.exists():
                        try:
                            Image.open(p).save(target)
                            print(f"  âœ… ëŒ€í‘œ ì´ë¯¸ì§€ ì €ì¥: {target.relative_to(ACTOR_IMAGES_DIR)}")
                        except Exception as e:
                            print(f"  âš ï¸  ì´ë¯¸ì§€ ë³µì‚¬ ì‹¤íŒ¨: {e}")
                            continue
                    
                    if target.exists():
                        # ìƒëŒ€ ê²½ë¡œ ì €ì¥ (ì˜ˆ: "ì†¡ê°•í˜¸/001.jpg")
                        rep_rel = f"{name}/{target.name}"
                        
            except Exception as e:
                print(f"  âŒ {p.name}: {e}")
                continue
        
        if not embs:
            print(f"  âš ï¸  {name}: ì–¼êµ´ì´ ê°ì§€ëœ ì´ë¯¸ì§€ê°€ ì—†ì–´ ì œì™¸ë©ë‹ˆë‹¤")
            continue
        
        print(f"  âœ… {face_detected_count}/{len(paths[:20])}ì¥ì—ì„œ ì–¼êµ´ ê°ì§€ ì„±ê³µ")
        
        # ì„ë² ë”© í–‰ë ¬ ìƒì„±
        X = np.stack(embs, axis=0)
        
        # í´ëŸ¬ìŠ¤í„°ë§ ë˜ëŠ” í‰ê·  ë²¡í„° ìƒì„±
        if clusters_per_actor > 1 and len(embs) >= clusters_per_actor:
            try:
                from sklearn.cluster import KMeans
                km = KMeans(n_clusters=clusters_per_actor, n_init=10, random_state=42)
                labels = km.fit_predict(X)
                
                for c in range(clusters_per_actor):
                    members = X[labels == c]
                    if members.size == 0:
                        continue
                    centroid = members.mean(axis=0)
                    centroid = centroid / (np.linalg.norm(centroid) + 1e-12)
                    vectors.append(centroid.astype("float32"))
                    meta.append({"name": name, "image_rel": rep_rel, "cluster": c})
                    
                print(f"  ğŸ“Š {clusters_per_actor}ê°œ í´ëŸ¬ìŠ¤í„° ìƒì„±")
            except Exception as e:
                print(f"  âš ï¸  í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨, í‰ê·  ë²¡í„° ì‚¬ìš©: {e}")
                # í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨ ì‹œ í‰ê·  ë²¡í„°ë¡œ í´ë°±
                mean_vec = np.mean(X, axis=0)
                mean_vec = mean_vec / (np.linalg.norm(mean_vec) + 1e-12)
                vectors.append(mean_vec.astype("float32"))
                meta.append({"name": name, "image_rel": rep_rel})
        else:
            # ë‹¨ìˆœ í‰ê·  ë²¡í„°
            mean_vec = np.mean(X, axis=0)
            mean_vec = mean_vec / (np.linalg.norm(mean_vec) + 1e-12)
            vectors.append(mean_vec.astype("float32"))
            meta.append({"name": name, "image_rel": rep_rel})
            print(f"  ğŸ“Š í‰ê·  ë²¡í„° ìƒì„± ì™„ë£Œ")
    
    print("\n" + "=" * 60)
    print(f"âœ… ë°°ìš° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {len(vectors)}ëª…")
    
    if not vectors:
        raise ValueError("ìœ íš¨í•œ ë°°ìš° ë²¡í„°ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ì— ì–¼êµ´ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    
    return np.stack(vectors, axis=0), meta


def main():
    parser = argparse.ArgumentParser(description="InsightFace ê¸°ë°˜ ë°°ìš° ì¸ë±ìŠ¤ ìƒì„±")
    parser.add_argument("--dataset-dir", type=str, help="ë°°ìš° ì´ë¯¸ì§€ ë£¨íŠ¸ í´ë”")
    parser.add_argument("--csv", type=str, help="'name,image_path' CSV íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--clusters-per-actor", type=int, default=1, help="ë°°ìš°ë³„ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (>=1)")
    args = parser.parse_args()

    DATA_DIR.mkdir(parents=True, exist_ok=True)

    # ë°ì´í„°ì…‹ ë¡œë“œ
    groups: Dict[str, List[Path]]
    if args.dataset_dir:
        print(f"ğŸ“ í´ë” ê¸°ë°˜ ë°ì´í„°ì…‹ ë¡œë“œ: {args.dataset_dir}")
        groups = iter_folder(Path(args.dataset_dir))
    elif args.csv:
        print(f"ğŸ“„ CSV ê¸°ë°˜ ë°ì´í„°ì…‹ ë¡œë“œ: {args.csv}")
        groups = iter_csv(Path(args.csv))
    else:
        raise SystemExit("âŒ --dataset-dir ë˜ëŠ” --csv ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤")

    if not groups:
        raise SystemExit("âŒ ë°ì´í„°ì…‹ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")

    print(f"âœ… {len(groups)}ëª…ì˜ ë°°ìš° ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

    # InsightFaceë¡œ ì„ë² ë”© ìƒì„±
    emb, meta = compute_actor_vectors(groups, clusters_per_actor=max(1, int(args.clusters_per_actor)))
    
    # ì €ì¥
    embeddings_path = DATA_DIR / "embeddings.npy"
    metadata_path = DATA_DIR / "metadata.json"
    
    np.save(embeddings_path, emb)
    with open(metadata_path, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)

    print(f"\n{'=' * 60}")
    print(f"âœ… ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ!")
    print(f"ğŸ“Š ë°°ìš° ìˆ˜: {emb.shape[0]}ëª…")
    print(f"ğŸ“ ë²¡í„° ì°¨ì›: {emb.shape[1]}")
    print(f"ğŸ“‚ ì €ì¥ ê²½ë¡œ:")
    print(f"   - {embeddings_path}")
    print(f"   - {metadata_path}")
    print(f"   - {ACTOR_IMAGES_DIR}")
    print(f"{'=' * 60}\n")


if __name__ == "__main__":
    main()
